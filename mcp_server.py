"""
Enercon RAG - MCP Server
Model Context Protocol server Î³Î¹Î± Claude Desktop integration
"""
import asyncio
import json
import sys
from typing import Any
import hashlib

# MCP imports
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent

# Pinecone
from pinecone import Pinecone
from dotenv import load_dotenv
import os

# Load environment
load_dotenv()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY", "")
INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "enercon")

if not PINECONE_API_KEY:
    print("Error: PINECONE_API_KEY not set", file=sys.stderr)
    sys.exit(1)

pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(INDEX_NAME)

# Create MCP Server
app = Server("enercon-rag")

@app.list_tools()
async def list_tools() -> list[Tool]:
    """List available tools"""
    return [
        Tool(
            name="rag_search",
            description="Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· ÏƒÏ„Î¿ Enercon RAG Knowledge Base. Î’ÏÎ¯ÏƒÎºÎµÎ¹ Î­Î³Î³ÏÎ±Ï†Î±, emails, ÎµÏ€Î±Ï†Î­Ï‚, Ï„Î¹Î¼Î­Ï‚ Ï†Ï‰Ï„Î¿Î²Î¿Î»Ï„Î±ÏŠÎºÏÎ½.",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Î¤Î¹ ÏˆÎ¬Ï‡Î½ÎµÎ¹Ï‚ (Ï€.Ï‡. 'inverter Huawei Ï„Î¹Î¼Î®', 'ÎµÏ€Î±Ï†Î® Î“Î¹Î¬Î½Î½Î·Ï‚', 'email Big Solar')"
                    },
                    "top_k": {
                        "type": "integer",
                        "description": "Î ÏŒÏƒÎ± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± (default: 5)",
                        "default": 5
                    }
                },
                "required": ["query"]
            }
        ),
        Tool(
            name="rag_add",
            description="Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î½Î­Î±Ï‚ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î±Ï‚ ÏƒÏ„Î¿ Enercon RAG (ÎµÏ€Î±Ï†Î®, ÏƒÎ·Î¼ÎµÎ¯Ï‰ÏƒÎ·, Ï„Î¹Î¼Î®, ÎºÎ»Ï€)",
            inputSchema={
                "type": "object",
                "properties": {
                    "text": {
                        "type": "string",
                        "description": "Î¤Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ (Ï€.Ï‡. 'Î•Ï€Î±Ï†Î®: Î“Î¹Î¬Î½Î½Î·Ï‚, Î¤Î·Î»: 6971234567')"
                    },
                    "title": {
                        "type": "string",
                        "description": "Î¤Î¯Ï„Î»Î¿Ï‚ Î³Î¹Î± ÎµÏÎºÎ¿Î»Î· Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ·"
                    },
                    "category": {
                        "type": "string",
                        "description": "ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±: contact, note, pricelist, inverter, panel, battery, email, quote",
                        "default": "note"
                    }
                },
                "required": ["text", "title"]
            }
        ),
        Tool(
            name="rag_stats",
            description="Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Ï„Î¿Ï… Enercon RAG - Ï€ÏŒÏƒÎ± Î­Î³Î³ÏÎ±Ï†Î±, ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯ÎµÏ‚ ÎºÎ»Ï€",
            inputSchema={
                "type": "object",
                "properties": {}
            }
        )
    ]

@app.call_tool()
async def call_tool(name: str, arguments: dict[str, Any]) -> list[TextContent]:
    """Execute a tool"""
    
    if name == "rag_search":
        query = arguments.get("query", "")
        top_k = arguments.get("top_k", 5)
        
        # Embed and search
        result = pc.inference.embed(
            model="multilingual-e5-large",
            inputs=[query],
            parameters={"input_type": "query"}
        )
        results = index.query(
            vector=result.data[0].values,
            top_k=top_k,
            include_metadata=True
        )
        
        # Format results
        output = f"ğŸ” Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î³Î¹Î±: {query}\n\n"
        for i, m in enumerate(results.matches, 1):
            title = m.metadata.get("title", "")
            category = m.metadata.get("category", "")
            text = m.metadata.get("text", "")[:300]
            score = m.score
            output += f"{i}. **{title}** [{category}] (score: {score:.2f})\n"
            output += f"   {text}...\n\n"
        
        if not results.matches:
            output += "Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±."
        
        return [TextContent(type="text", text=output)]
    
    elif name == "rag_add":
        text = arguments.get("text", "")
        title = arguments.get("title", "")
        category = arguments.get("category", "note")
        
        # Create embedding and upsert
        doc_id = hashlib.md5(text.encode()).hexdigest()[:16]
        result = pc.inference.embed(
            model="multilingual-e5-large",
            inputs=[text],
            parameters={"input_type": "passage"}
        )
        index.upsert(vectors=[{
            "id": doc_id,
            "values": result.data[0].values,
            "metadata": {
                "text": text[:8000],
                "category": category,
                "title": title
            }
        }])
        
        return [TextContent(
            type="text",
            text=f"âœ… Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎµ ÏƒÏ„Î¿ RAG!\n\n**Î¤Î¯Ï„Î»Î¿Ï‚:** {title}\n**ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±:** {category}\n**ID:** {doc_id}"
        )]
    
    elif name == "rag_stats":
        stats = index.describe_index_stats()
        
        # Get category breakdown
        result = pc.inference.embed(
            model="multilingual-e5-large",
            inputs=["solar inverter panel battery email contact"],
            parameters={"input_type": "query"}
        )
        results = index.query(
            vector=result.data[0].values,
            top_k=100,
            include_metadata=True
        )
        
        categories = {}
        for m in results.matches:
            cat = m.metadata.get("category", "unknown")
            categories[cat] = categories.get(cat, 0) + 1
        
        output = f"ğŸ“Š **Enercon RAG Stats**\n\n"
        output += f"**Total vectors:** {stats.total_vector_count}\n\n"
        output += "**Î‘Î½Î¬ ÎºÎ±Ï„Î·Î³Î¿ÏÎ¯Î±:**\n"
        for cat, count in sorted(categories.items()):
            output += f"- {cat}: {count}\n"
        
        return [TextContent(type="text", text=output)]
    
    return [TextContent(type="text", text=f"Unknown tool: {name}")]

async def main():
    async with stdio_server() as (read_stream, write_stream):
        await app.run(read_stream, write_stream, app.create_initialization_options())

if __name__ == "__main__":
    asyncio.run(main())
